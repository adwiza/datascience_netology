{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee8758d",
   "metadata": {},
   "source": [
    "1. Сверточная сеть для классификации\n",
    "2. Active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb69491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Masking\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(1228)\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.layers import Convolution1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import  concatenate\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4490c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(['pos', 'neg'])\n",
    "y_train_cat = to_categorical(le.transform(y_train), 2)\n",
    "y_test_cat = to_categorical(le.transform(y_test), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e73e1f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msequences\u001b[49m \u001b[38;5;241m-\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X_text_train)\n\u001b[0;32m      2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m pad_sequences(sequences, maxlen\u001b[38;5;241m=\u001b[39mTEXT_LENGTH)\n\u001b[0;32m      3\u001b[0m sequences \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X_text_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sequences' is not defined"
     ]
    }
   ],
   "source": [
    "sequences - tokenizer.texts_to_sequences(X_text_train)\n",
    "X_train = pad_sequences(sequences, maxlen=TEXT_LENGTH)\n",
    "sequences = tokenizer.texts_to_sequences(X_text_test)\n",
    "X_test = pad_sequences(sequences, maxlen=TEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d32e6fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Embedding(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mnum_words, maxlen, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m      4\u001b[0m words \u001b[38;5;241m=\u001b[39m wordsEmbeddingLayer(words_input)\n\u001b[0;32m      5\u001b[0m words_conv \u001b[38;5;241m=\u001b[39m Convolution1D(filters\u001b[38;5;241m=\u001b[39mnb_filter,\n\u001b[0;32m      6\u001b[0m                            kernel_size\u001b[38;5;241m=\u001b[39mfilter_length,\n\u001b[0;32m      7\u001b[0m                            padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m                            activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                            strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)(words)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(tokenizer.num_words, maxlen, trainable=True))\n",
    "model.add(Convolution1D(filters=nb_filter,\n",
    "                           kernel_size=filter_length,\n",
    "                           padding='same',\n",
    "                           activation='relu',\n",
    "                           strides=1))\n",
    "\n",
    "model.add(GlobalMaxPooling1D()(words_conv))\n",
    "model.add(Dropout(.5)(output))\n",
    "model.add(Dense(hidden_dims, activation='tanh', kenel_regularizer=keras.regularizers.l2()))\n",
    "model.add(Dropout(.25)(output))\n",
    "model.add(Dense(2, activation='softmax', kenel_regularizer=keras.regularizers.l2()))\n",
    "model = Model(inputs=[words_input], outputs=[output])\n",
    "model.compile()\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78335a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
