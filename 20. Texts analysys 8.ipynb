{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2dad99e",
   "metadata": {},
   "source": [
    "# Word Mover's Distance \n",
    "## по статье Matthew J. Kusner'а \"From Word Embeddings to Document Distances\" [1]\n",
    "\n",
    "![img](https://raw.githubusercontent.com/mkusner/wmd/master/fig1.png)\n",
    "\n",
    "\n",
    "Формулировка задачи определения сходства между двумя предложениями как задачи транспортной задачи:\n",
    "\n",
    "1. Пусть $X \\in \\mathbb{R}^{d \\times n}$ – матрица эмбеддингов,  $d$ – размерность эмбеддинга, $n$ - количество слов;\n",
    "2. Вектор-документ в векторной модели: $d \\in \\mathbb{R}^n$ состоит из $c_i = \\texttt{count}(word_i, doc)$\n",
    "3. Нормированный вектор-документ: $d_i = \\frac{c_i}{\\sum_i c_i}$\n",
    "4. Расстояние между словами: $\\texttt{cost}(word_i, word_j) = ||x_i - x_j||_2$\n",
    "\n",
    "Дано два документа, $d, d'$. Пусть  $T \\in \\mathbb{R}^{n \\times n}$, $T_{ij} \\ge 0$ – матрица потока показывает расстояния от каждого слова $d$ до $d'$.\n",
    "\n",
    "Транспортная задача:\n",
    "\n",
    "$\\min_{T \\ge 0} \\sum_{i,j}^n T_{ij}\\texttt{cost}(word_i, word_j) $\n",
    "\n",
    "при условии:\n",
    "\n",
    "$\\sum_{j} T_{ij} = d_i$\n",
    "\n",
    "$\\sum_{i} T_{ij} = d'_j$.\n",
    "\n",
    "Задача решается средствами линейного программирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386dc85f",
   "metadata": {},
   "source": [
    "### Примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a193ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "start_nb = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def95ad",
   "metadata": {},
   "source": [
    "Используем fasttext эмбеддинги Facebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860f0249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adwiz\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell took 659.15 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "import os\n",
    "\n",
    "from gensim.models import *\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('datasets/nlp/wiki.ru.vec', binary=False)\n",
    "print('Cell took %.2f seconds to run.' % (time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97fb851",
   "metadata": {},
   "source": [
    "Вычисляем попарное сходство между тремя тестовыми предложениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5f8d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between s1 and s2 = 1.3363\n",
      "distance between s1 and s3 = 2.5128\n",
      "distance between s2 and s3 = 2.5454\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Ученые обнаружили ископаемую ящерицу с парой теменных глаз'\n",
    "s2 = 'У палеогеновой ящерицы нашли вторую пару глаз'\n",
    "s3 = 'Apple через два года откажется от процессоров Intel'\n",
    "\n",
    "distance = model.wmdistance(s1, s2)\n",
    "print ('distance between s1 and s2 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s1, s3)\n",
    "print ('distance between s1 and s3 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s2, s3)\n",
    "print ('distance between s2 and s3 = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed0a5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between s1 and s2 = 0.3252\n",
      "distance between s1 and s3 = 0.5703\n",
      "distance between s2 and s3 = 0.5574\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)\n",
    "\n",
    "distance = model.wmdistance(s1, s2)\n",
    "print ('distance between s1 and s2 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s1, s3)\n",
    "print ('distance between s1 and s3 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s2, s3)\n",
    "print ('distance between s2 and s3 = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1fb7d1",
   "metadata": {},
   "source": [
    "Повторим тоже самое на корпусе твиттов [1]. \n",
    "\n",
    "Считываем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd3b70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adwiz\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tuser</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfriend</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906692374446080</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>pleease_shut_up</td>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7569</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906692693221377</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>alinakirpicheva</td>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11825</td>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906695083954177</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>EvgeshaRe</td>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1273</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408906695356973056</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>ikonnikova_21</td>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1549</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408906761416867842</td>\n",
       "      <td>1386325943</td>\n",
       "      <td>JumpyAlex</td>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tdate            tuser  \\\n",
       "0  408906692374446080  1386325927  pleease_shut_up   \n",
       "1  408906692693221377  1386325927  alinakirpicheva   \n",
       "2  408906695083954177  1386325927        EvgeshaRe   \n",
       "3  408906695356973056  1386325927    ikonnikova_21   \n",
       "4  408906761416867842  1386325943        JumpyAlex   \n",
       "\n",
       "                                               ttext  ttype  trep  tfav  \\\n",
       "0  @first_timee хоть я и школота, но поверь, у на...      1     0     0   \n",
       "1  Да, все-таки он немного похож на него. Но мой ...      1     0     0   \n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...      1     0     1   \n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...      1     0     1   \n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...      1     0     0   \n",
       "\n",
       "   tstcount   tfol  tfriend  listcount  \n",
       "0         0   7569       62         61  \n",
       "1         0  11825       59         31  \n",
       "2         0   1273       26         27  \n",
       "3         0   1549       19         17  \n",
       "4         0    597       16         23  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('datasets/nlp/positive.csv', sep=';', header=None,  index_col=False,\n",
    "                  names = [ 'id', 'tdate', 'tuser', 'ttext', 'ttype',\n",
    "                          'trep', 'tfav', 'tstcount', 'tfol','tfriend', 'listcount'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd1aea",
   "metadata": {},
   "source": [
    "Предобработка (приводим к нижнему регистру, удаляем стоп-слова и не кириллические символы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9918e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile('[А-Яа-яё]+')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return ' '.join(regex.findall(text))\n",
    "\n",
    "def remove_stopwords(text, stopwords=stopwords.words('russian')):\n",
    "    try:\n",
    "        return ' '.join([token for token in text.split() if not token in stopwords])\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "raw_tweets = data.ttext.tolist()\n",
    "data.ttext = data.ttext.str.lower()\n",
    "data.ttext = data.ttext.apply(words_only)\n",
    "data.ttext = data.ttext.apply(remove_stopwords)\n",
    "\n",
    "tweets = [tweet.split() for tweet in data.ttext.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "079360f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-яё]+\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return \" \".join(regex.findall(text))\n",
    "\n",
    "\n",
    "\n",
    "def  remove_stopwords(text, stopwords = stopwords.words('russian')):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in stopwords])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "raw_tweets = data.ttext.tolist()\n",
    "data.ttext = data.ttext.str.lower()\n",
    "data.ttext = data.ttext.apply(words_only)\n",
    "data.ttext = data.ttext.apply(remove_stopwords)   \n",
    "\n",
    "\n",
    "tweets = [tweet.split() for tweet in data.ttext.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56523340",
   "metadata": {},
   "source": [
    "Инициализируем класс для вычисления близостей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411e879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities import WmdSimilarity\n",
    "num_best = 10\n",
    "instance = WmdSimilarity(tweets, model, num_best=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b6235",
   "metadata": {},
   "source": [
    "Задаем документ-запрос и предобрабатываем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b5de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'Ученые обнаружили ископаемую ящерицу с парой теменных глаз'\n",
    "query = words_only(s1).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da80b6",
   "metadata": {},
   "source": [
    "Поиск по запросу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b1b077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = instance[query]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed60318",
   "metadata": {},
   "source": [
    "И результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d12c7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['ученые', 'обнаружили', 'ископаемую', 'ящерицу', 'с', 'парой', 'теменных', 'глаз']\n",
      "2401\n",
      "ученые установили пищу пережевывать давятся витамины пережевывать люди\n",
      "\n",
      "12140\n",
      "девушку которой врачи обнаружили рак вообще интересный\n",
      "\n",
      "94458\n",
      "ученые скрестили гиену пнем получили гиенологическое дерево\n",
      "\n",
      "29935\n",
      "американские ученые выяснили недосыпании детей виноваты родители это ржачно поделиться\n",
      "\n",
      "109592\n",
      "всеееее выкололи тебе глаз пролезли мозг\n",
      "\n",
      "46433\n",
      "читали портал ниасилили бровь глаз говориться статью растащить цитаты\n",
      "\n",
      "114425\n",
      "сначала глаз сломался мозг треснул\n",
      "\n",
      "93210\n",
      "мандаринку приложи говорят помогает сразу глаз пройдёт\n",
      "\n",
      "56187\n",
      "отлично завтра приду работу баклашкой словами ученые доказали\n",
      "\n",
      "4092\n",
      "сидят глаз будем палиться\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Query:', query)\n",
    "for i in range(10):\n",
    "    print(sims[i][0])\n",
    "    print(raw_tweets[sims[i][0]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d1059",
   "metadata": {},
   "source": [
    "## Источники \n",
    "1. Kusner, Matt, Yu Sun, Nicholas Kolkin, and Kilian Weinberger. \"From word embeddings to document distances.\" In International Conference on Machine Learning, pp. 957-966. 2015.\n",
    "2. Ю. В. Рубцова. Построение корпуса текстов для настройки тонового классификатора // Программные продукты и системы, 2015, №1(109), –С.72-78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446d80a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
